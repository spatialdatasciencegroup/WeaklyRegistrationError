{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Candidate Generation Module\n",
    "\n",
    "Take Shapefile, create candidate segments.\n",
    "\n",
    "---\n",
    "\n",
    "### `Expected Data`:\n",
    "\n",
    "- **Annotations Shapefile:**\n",
    "    Holds annotation to be split into segments for candidate generation.\n",
    "\n",
    "- **Ground Truth Shapefile:**\n",
    "    Holds Ground Truth annotation for candidate set quality evaluation.\n",
    "\n",
    "\n",
    "### `Output Data`:\n",
    "- **Candidate Frames:**\n",
    "    One Shapefile for every segment, holding a set of offset replacement candidates.\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiang-ws1/.virtualenvs/geo_errors/lib/python3.7/site-packages/geopandas/_compat.py:88: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.8.1-CAPI-1.13.3). Conversions between both will be slow.\n",
      "  shapely_geos_version, geos_capi_version_string\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe segment_sets_scene02_04:testing initial pmap for cropping\n",
      "Parameters Confirmed.\n",
      "\n",
      "Wed at 09:28:46PM\n"
     ]
    }
   ],
   "source": [
    "# -- Module Information --\n",
    "\n",
    "import time, os, sys\n",
    "from lib.ModuleTools import *\n",
    "from lib.GeoTools import *\n",
    "from lib.ShapeTools import *\n",
    "from lib.EMTools import *\n",
    "import lib.fixclip as fixclip\n",
    "import shapely.geometry as shp\n",
    "from pyproj import Transformer\n",
    "\n",
    "import rasterio.features as rfeat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_data = {\n",
    "    'name': 'Candidates-Scene02', # Module Name\n",
    "    'desc': 'Create Candidate Set from Shapefiles for second dataset', # Module Description\n",
    "    'test_name': 'segment_sets_scene02', # Default test name\n",
    "    'csv': 'segments_scene02.csv', # Csv path\n",
    "    'verbose': True # Default verbosity\n",
    "}\n",
    "\n",
    "test = ModuleTest(module_data)\n",
    "\n",
    "\n",
    "# -- Parameters --\n",
    "\n",
    "\n",
    "\n",
    "# Candidate Gen Config\n",
    "Config = {}\n",
    "# Number of candidate pairs to be generated for each line segment \n",
    "candidatePairs = wrap(30, Config)\n",
    "# length of line segments when parsing source. Measured in meters\n",
    "segmentLength = wrap(10, Config)\n",
    "# Distance from source line to generate candidate tuples\n",
    "baseOffset = wrap(1.5, Config)  \n",
    "\n",
    "\n",
    "\n",
    "### Multiplier for offset\n",
    "# Increase candidate offset by multiplication. Set to zero to incrememnt linearly\n",
    "exp_mod = wrap(0, Config) \n",
    " \n",
    "test.Pgroup('Candidate Generation Config', Config)\n",
    "\n",
    "\n",
    "\n",
    "# -- Input Data --\n",
    "# - Raster and shape data -\n",
    "InputData = {}\n",
    "# Shapefile annotations for label\n",
    "annotation = wrap_fp('/data/GeometricErrors/Scene02/small_crop/shapes/imperfect_lines_smaller_dataset.shp', InputData)\n",
    "# Raster to consider (if cropping) !! Need to use predicted class map, training raster is a tilted rectangle causing the bounding box to be larger than pmap\n",
    "raster = wrap_fp(\"/data/GeometricErrors/tests/aaai_system/EM_Iteration_s02/aaai_emtest_s02_01/Baseline/pmap_baseline.tif\", InputData)\n",
    "\n",
    "test.Fgroup('Shapes', InputData)\n",
    "\n",
    "# --------------------\n",
    "if test.verbose:\n",
    "    print(\"Parameters Confirmed.\")\n",
    "    from datetime import datetime as dt \n",
    "    print(dt.now().strftime('\\n%a at %I:%M:%S%p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.affinity import translate\n",
    "import lib.LineGen as lg\n",
    "import geopandas as gpd\n",
    "import rasterio.mask as msk\n",
    "\n",
    "def Get_Candidates(seg_gdf, pair_count, dist, exp_mod=1.2):\n",
    "    \"\"\" Generate Candidate Frames from cut linestring Frame.\n",
    "\n",
    "    Options:\n",
    "    pair_count: number of candidate pairs per segment\n",
    "    dist: offset for candidate pairs. Increases linearly then exponentially.\n",
    "    exp_mod: offset multiplier for outer candidates.\n",
    "    \"\"\"\n",
    "    # Will store one GeoDataframe for each segment, holding that segment's candidates\n",
    "    frames = []\n",
    "\n",
    "    # Iterate over linestring segments in seg_gdf\n",
    "    for line in seg_gdf.geometry:\n",
    "        \n",
    "        # Create Candidate List, starting with the original linestring\n",
    "        candidates = [line]\n",
    "\n",
    "        # Clear the offset value\n",
    "        off_dist = 0\n",
    "        \n",
    "        # Iterate i over the number of candidate pairs to be generated.\n",
    "        for i in range(pair_count):\n",
    "            \n",
    "            # Increment\n",
    "            off_dist += dist\n",
    "            \n",
    "            # Check for outer pairs multiplier \n",
    "            if (exp_mod > 0.0) and (i*2 > pair_count):\n",
    "                off_dist *= exp_mod                \n",
    "                \n",
    "\n",
    "            # Parse the offset distance into tuple (x_off, y_off)  \n",
    "            (xVal, yVal) = lg.Weight_Dist(line=line, dist=off_dist)\n",
    "            \n",
    "            # Determine line's slope, Translate from tuple\n",
    "            if lg.Get_Slope(line) > 0:\n",
    "                candidates.append(translate(line, xoff=-xVal, yoff=yVal))\n",
    "                candidates.append(translate(line, xoff=xVal, yoff=-yVal)) \n",
    "            else:\n",
    "                candidates.append(translate(line, xoff=xVal, yoff=yVal))\n",
    "                candidates.append(translate(line, xoff=-xVal, yoff=-yVal)) \n",
    "                \n",
    "        # Add the candidate frame to output.\n",
    "        frames.append(gpd.GeoDataFrame(geometry=candidates, crs=seg_gdf.crs))\n",
    "\n",
    "    return frames\n",
    "\n",
    "def CropCandidates(candidate_gdf, raster_poly, buff):\n",
    "    \"\"\" Crop Candidate Frames. \"\"\"\n",
    "\n",
    "    copy_gdf = GDF_Buffer(candidate_gdf, buff)\n",
    "\n",
    "    # Save Frame\n",
    "    metadata = {key: [] for key in candidate_gdf.columns}\n",
    "    for idx, geom in enumerate(copy_gdf.geometry):\n",
    "        if raster_poly.contains(geom):\n",
    "            for key, data in candidate_gdf.items():\n",
    "                metadata[key].append(data[idx])\n",
    "\n",
    "    if len(metadata['geometry']) < 2:\n",
    "        print(\"Warning (CropCandidates): Less than 2 of the candidates exist on the raster. Checked {}. Saving as shapefile and omitting from candidates.\".format(len(candidate_gdf.geometry)))\n",
    "        return 'omit'\n",
    "\n",
    "    return gpd.GeoDataFrame(metadata, crs=candidate_gdf.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Segments:       547\n",
      "Candidates Per Seg:   61\n",
      "Total Candidates (~): 32821\n",
      "Create Candidate Set (01) Complete.\n",
      "\n",
      "Wed at 09:30:07PM\n"
     ]
    }
   ],
   "source": [
    "# Code Section \n",
    "section_tstamp = time.time()\n",
    "section_name = 'Create Candidate Set'\n",
    "# --------------------\n",
    "\n",
    "# Create Raster Bounding Box Polygon for removing out-of-bounds candidates\n",
    "# CRS Transformer\n",
    "trans = Transformer.from_crs(raster.crs, annotation.crs, always_xy=True)\n",
    "# Bounding Polygon\n",
    "(mx,my,Mx,My) = raster.bounds\n",
    "raster_poly = shp.box(mx,my,Mx,My)\n",
    "\n",
    "# Remove Multi-Geometries\n",
    "annotation = annotation.to_crs(raster.crs)\n",
    "annotation = Flatten_Frame(annotation)\n",
    "\n",
    "# Split source_lines into fixed-length segments\n",
    "cutLines = Segment_GDF(gdf=annotation, segment_length=segmentLength)\n",
    "\n",
    "# Generate candidates for each segment. \n",
    "candidateFrames = Get_Candidates(seg_gdf=cutLines, pair_count=candidatePairs, dist=baseOffset, exp_mod=exp_mod)\n",
    "\n",
    "# crop and save candidates\n",
    "allSegments = []\n",
    "for idx, cFrame in enumerate(candidateFrames):\n",
    "    cropped = CropCandidates(cFrame, raster_poly, 2)\n",
    "    if not isinstance(cropped, str):\n",
    "        fp = os.path.join(test.Folder('segments'), 'set{:02}{}.shp'.format(idx, test.end))\n",
    "        cropped.to_file(fp)\n",
    "        for geom in cropped.geometry:\n",
    "            allSegments.append(geom)\n",
    "        \n",
    "# Save all segments as single frame\n",
    "allSegments = gpd.GeoDataFrame(geometry=allSegments, crs=annotation.crs) \n",
    "allSegments.to_file(test.dir + '/all{}.shp'.format(test.end))\n",
    "\n",
    "print(\"Total Segments:      \", len(cutLines.geometry))\n",
    "print(\"Candidates Per Seg:  \", ((candidatePairs*2) + 1))\n",
    "print(\"Total Candidates (~):\", (len(candidateFrames)*(candidatePairs*2) + 1))\n",
    "\n",
    "# --------------------\n",
    "section_data = {'time': time.time()-section_tstamp, 'stamp': section_tstamp}\n",
    "test.Section(section_name, section_data)\n",
    "# --------------------\n",
    "if test.verbose:\n",
    "    print(\"{} ({:02}) Complete.\".format(section_name, len(test.sectionNames)))\n",
    "    print(dt.now().strftime('\\n%a at %I:%M:%S%p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to markdown file, indexed on csv.\n",
      "\n",
      "Wed at 09:30:07PM\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Save Information and Index Test. \"\"\"\n",
    "\n",
    "# Index in master csv\n",
    "test.index()\n",
    "\n",
    "# Write Info to Markdown\n",
    "test.markdown()\n",
    "\n",
    "# ------------------------\n",
    "if test.verbose:\n",
    "    print(\"Data successfully saved to markdown file, indexed on csv.\") \n",
    "    print(dt.now().strftime('\\n%a at %I:%M:%S%p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3808\n"
     ]
    }
   ],
   "source": [
    "print(raster.width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_errors",
   "language": "python",
   "name": "geo_errors"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
